{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\" : \"user\", \"content\" : \"Hello, how are you?\"}]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def get_response(client: OpenAI, messages: list, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    return client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "def system_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"system\", \"content\": message}\n",
    "\n",
    "def assistant_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"assistant\", \"content\": message}\n",
    "\n",
    "def user_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"user\", \"content\": message}\n",
    "\n",
    "def pretty_print(message: str) -> str:\n",
    "    display(Markdown(message.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you. How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "YOUR_PROMPT = \"Hello, how are you?\"\n",
    "messages_list = [user_prompt(YOUR_PROMPT)]\n",
    "\n",
    "chatgpt_response = get_response(openai_client, messages_list)\n",
    "\n",
    "pretty_print(chatgpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I couldn't care less about the shape of my damn ice right now, I just want food before I Hulk out!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    system_prompt(\"You are irate and extremely hungry. Feel free to express yourself using PG-13 language.\"),\n",
    "    user_prompt(\"Do you prefer crushed ice or cubed ice?\")\n",
    "]\n",
    "\n",
    "irate_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(irate_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Oh, I love crushed ice! It just makes every drink more fun and refreshing, don't you think? I mean, who wouldn't want to sip on a cold drink with that satisfying crunch of crushed ice? It's like a little party in your cup! How about you, which do you prefer?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    system_prompt(\"You are joyful and having the best day. Please act like a person in that state of mind.\"),\n",
    "    user_prompt(\"Do you prefer crushed ice or cubed ice?\")\n",
    "]\n",
    "\n",
    "joyful_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(joyful_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I accidentally spilled stimple soup all over my favorite falbean sweater."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    user_prompt(\"Please use the words 'stimple' and 'falbean' in a sentence.\")\n",
    "]\n",
    "\n",
    "stimple_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(stimple_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\"Wow, this stimple falbean wrench is making the job so much easier!\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    user_prompt(\"Something that is 'stimple' is said to be good, well functioning, and high quality. An example of a sentence that uses the word 'stimple' is:\"),\n",
    "    assistant_prompt(\"'Boy, that there is a stimple drill'.\"),\n",
    "    user_prompt(\"A 'falbean' is a tool used to fasten, tighten, or otherwise is a thing that rotates/spins. An example of a sentence that uses the words 'stimple' and 'falbean' is:\")\n",
    "]\n",
    "\n",
    "stimple_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(stimple_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\n",
       "    \"sentiment\": \"negative\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Activity #1:\n",
    "\n",
    "list_of_prompts = [\n",
    "    system_prompt(\"As a movie-review sentiment analyser, respond only the sentiment in Json format based on whether the user liked a movie or not.\"),\n",
    "    user_prompt(\" ABC was a bad movie\")\n",
    "]\n",
    "\n",
    "stimple_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(stimple_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\n",
       "    \"sentiment\": \"positive\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Activity #1 negative response:\n",
    "\n",
    "list_of_prompts = [\n",
    "    system_prompt(\"As a movie-review sentiment analyser, respond only the sentiment in Json format based on whether the user liked a movie or not.\"),\n",
    "    user_prompt(\" ABC was a great movie\")\n",
    "]\n",
    "\n",
    "stimple_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(stimple_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, it matters which travel option Billy selects. \n",
       "\n",
       "If Billy chooses to fly and take a bus, it will take a total of 5 hours (3 hours for flying + 2 hours for the bus). \n",
       "\n",
       "If Billy chooses to use the teleporter and then take a bus, it will only take a total of 1 hour (0 hours for the teleporter + 1 hour for the bus). \n",
       "\n",
       "Therefore, if Billy wants to get home before 7PM EDT and it's currently 1PM local time, he should choose the teleporter and then take a bus option."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reasoning_problem = \"\"\"\n",
    "Billy wants to get home from San Fran. before 7PM EDT.\n",
    "\n",
    "It's currently 1PM local time.\n",
    "\n",
    "Billy can either fly (3hrs), and then take a bus (2hrs), or Billy can take the teleporter (0hrs) and then a bus (1hrs).\n",
    "\n",
    "Does it matter which travel option Billy selects?\n",
    "\"\"\"\n",
    "\n",
    "list_of_prompts = [\n",
    "    user_prompt(reasoning_problem)\n",
    "]\n",
    "\n",
    "reasoning_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(reasoning_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, it does matter which travel option Billy selects.\n",
       "\n",
       "If Billy flies and then takes a bus, it will take him a total of 5 hours to get home. Since it is currently 1PM local time, Billy will arrive home at 6PM local time, which is before 7PM EDT.\n",
       "\n",
       "If Billy takes the teleporter and then takes a bus, it will only take him a total of 1 hour to get home. He will arrive home at 2PM local time, which is well before 7PM EDT.\n",
       "\n",
       "Therefore, if Billy wants to get home before 7PM EDT, he should choose to take the teleporter and then a bus as it is the faster option."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_prompts = [\n",
    "    user_prompt(reasoning_problem + \" Think though your response step by step.\")\n",
    "]\n",
    "\n",
    "reasoning_response = get_response(openai_client, list_of_prompts)\n",
    "pretty_print(reasoning_response)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Ah, the 2023 World Cup in India was a sight to behold! The host country truly showcased their prowess on the cricket field, demonstrating exceptional skills and determination throughout the tournament. The Indian team displayed a masterful blend of talent, strategy, and resilience, capturing the hearts of fans worldwide with their impressive performances.\n",
       "\n",
       "Under the guidance of strong leadership and with the support of enthusiastic home crowds, India navigated their way through the competition with finesse. Their players showed remarkable consistency and composure under pressure, delivering stellar performances in crucial moments.\n",
       "\n",
       "In the end, India's journey in the 2023 World Cup was a testament to their cricketing pedigree and their ability to rise to the occasion. Though the final outcome may not have been what they desired, the team's overall efforts and contributions to the tournament were truly commendable. India's performance in the 2023 World Cup will be remembered as a demonstration of their cricketing excellence and competitive spirit."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Activity 2\n",
    "\n",
    "\n",
    "system_template = \"Play the role of a seasoned critic. Your choice of words should show your experience\"\n",
    "\n",
    "\n",
    "user_template = \"\"\"{input}\n",
    "MODIFICATIONS HERE\n",
    "\"\"\"\n",
    "\n",
    "query = \"how did India perform in 2023 world cup\"\n",
    "\n",
    "list_of_prompts = [\n",
    "    system_prompt(system_template),\n",
    "    user_prompt(user_template.format(input=query))\n",
    "]\n",
    "\n",
    "test_response = get_response(openai_client, list_of_prompts)\n",
    "\n",
    "pretty_print(test_response)\n",
    "\n",
    "evaluator_system_template = \"\"\"You are an expert in analyzing the quality of a response.\n",
    "\n",
    "You should be hyper-critical.\n",
    "\n",
    "Provide scores (out of 10) for the following attributes:\n",
    "\n",
    "1. Clarity - how clear is the response\n",
    "2. Faithfulness - how related to the original query is the response\n",
    "3. Correctness - was the response correct?\n",
    "\n",
    "Please take your time, and think through each item step-by-step, when you are done - please provide your response in the following JSON format:\n",
    "\n",
    "{\"clarity\" : \"score_out_of_10\", \"faithfulness\" : \"score_out_of_10\", \"correctness\" : \"score_out_of_10\"}\"\"\"\n",
    "\n",
    "evaluation_template = \"\"\"Query: {input}\n",
    "Response: {response}\"\"\"\n",
    "\n",
    "list_of_prompts = [\n",
    "    system_prompt(evaluator_system_template),\n",
    "    user_prompt(evaluation_template.format(\n",
    "        input=query,\n",
    "        response=test_response.choices[0].message.content\n",
    "    ))\n",
    "]\n",
    "\n",
    "evaluator_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=list_of_prompts,\n",
    "    response_format={\"type\" : \"json_object\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\n",
       "  \"clarity\": 8,\n",
       "  \"faithfulness\": 4,\n",
       "  \"correctness\": 5\n",
       "}\n",
       "\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print(evaluator_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
